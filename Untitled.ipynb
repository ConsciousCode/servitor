{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a15bb38-6239-4e41-86ce-4d6b29fd19f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (1432857271.py, line 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 64\u001b[0;36m\u001b[0m\n\u001b[0;31m    buf = buf[m.end():])\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from functools import wraps\n",
    "from typing import Generator, Literal, NamedTuple, TypeAlias\n",
    "\n",
    "EOF = object()\n",
    "\n",
    "def coroutine(fn):\n",
    "\t'''\n",
    "\tWraps a generator which is intended to be used as a pure coroutine by\n",
    "\t.send()ing it values. The only thing that the wrapper does is calling\n",
    "\t.next() for the first time which is required by Python generator protocol.\n",
    "\t'''\n",
    "\t@wraps(fn)\n",
    "\tdef wrapper(*args, **kwargs):\n",
    "\t\tg = fn(*args, **kwargs)\n",
    "\t\tnext(g)\n",
    "\t\treturn g\n",
    "\treturn wrapper\n",
    "\n",
    "LEXEMERE = re.compile(r\"\"\"\\s*(?:\n",
    "\t# Empty string\n",
    "\t((?:''|\"\"|``)(?!$)|(?:'{6}|\"{6}|`{6}))|\n",
    "\t# String with content\n",
    "\t('''|\\\"\"\"|```|['\"`](?!$))|\n",
    "\t# Unquoted string\n",
    "\t((?:\\\\.|[^\\\\\\n:,\\(\\)\\[\\]\\{\\}'\"`]+?)+)|\n",
    "\t(\\S) # Other\n",
    ")\"\"\", re.X)\n",
    "UNQUOTED_RE = re.compile(r\"\"\"(?:\\\\.|[^\\\\\\n:,\\(\\)\\[\\]\\{\\}'\"`]+?)+\"\"\")\n",
    "\n",
    "'''\n",
    "In LMON, all values are strings or aggregates. Defer parsing to the user\n",
    "Inspirations:\n",
    "* ijson\n",
    "* HJSON\n",
    "* Strict YAML (https://hitchdev.com/strictyaml/features-removed/ - no implicit typing)\n",
    "'''\n",
    "\n",
    "class Lexemere(NamedTuple):\n",
    "\t'''\n",
    "\tLexeme + -mere, a part of a lexeme. Originally SubLexeme, but then I saw the regex\n",
    "\tname LEXEME_RE and \"lexemere\" just makes so much sense.\n",
    "\t'''\n",
    "\tkind: Literal['atom', 'start', 'cont', 'end']\n",
    "\tvalue: str\n",
    "\n",
    "@coroutine\n",
    "def lexer(target):\n",
    "\ttry:\n",
    "\t\tbuf = yield\n",
    "\texcept GeneratorExit:\n",
    "\t\tbuf = ''\n",
    "\twhile True:\n",
    "\t\tprint(buf)\n",
    "\t\tif m := LEXEMERE.match(buf):\n",
    "\t\t\t# Empty string\n",
    "\t\t\tif m[1]:\n",
    "\t\t\t\ttarget.send(Lexemere('atom', m[1]))\n",
    "\t\t\t\tbuf = buf[m.end():]\n",
    "\t\t\t# Quoted string\n",
    "\t\t\telif q := m[2]:\n",
    "\t\t\t\tSTREND_RE = re.compile(rf\"(?:\\\\.|(?!{q})[^\\\\]+?)*{q}\")\n",
    "\t\t\t\t\n",
    "\t\t\t\tbuf = buf[m.end():])\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Check if the string is fully consumed\n",
    "\t\t\t\tif m := STREND_RE.match(buf):\n",
    "\t\t\t\t\ttarget.send(Lexemere('atom', q + m[0]))\n",
    "\t\t\t\t\tbuf = buf[m.end():]\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\ttarget.send(Lexemere('start', q + buf))\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Incomplete string, wait for more data\n",
    "\t\t\t\twhile True:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tbuf = yield\n",
    "\t\t\t\t\texcept GeneratorExit:\n",
    "\t\t\t\t\t\tbuf = ''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif m := STREND_RE.match(buf):\n",
    "\t\t\t\t\t\ttarget.send(Lexemere('end', q + m[1]))\n",
    "\t\t\t\t\t\tbuf = buf[m.end():]\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\ttarget.send(Lexemere('cont', buf))\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Unquoted string\n",
    "\t\t\telif m[3]:\n",
    "\t\t\t\ttarget.send(Lexemere('start', m[3]))\n",
    "\t\t\t\tif buf := buf[m.end():]:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\twhile True:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tbuf = yield\n",
    "\t\t\t\t\texcept GeneratorExit:\n",
    "\t\t\t\t\t\tbuf = ''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif m := UNQUOTED_RE.match(buf):\n",
    "\t\t\t\t\t\ttarget.send(Lexemere('cont', m[0]))\n",
    "\t\t\t\t\t\tif buf := buf[m.end():]:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Punctuators\n",
    "\t\t\telif buf[4] in '()[]{}:,':\n",
    "\t\t\t\ttarget.send(Lexemere('atom', buf[0]))\n",
    "\t\t\t\tbuf = buf[1:]\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# ???\n",
    "\t\t\telse:\n",
    "\t\t\t\traise ValueError(f\"Unknown sublexeme {m[0]!r}\")\n",
    "\t\t# Nothing matched, consume more data\n",
    "\t\telse:\n",
    "\t\t\tif buf:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tbuf = yield\n",
    "\t\t\t\texcept GeneratorExit:\n",
    "\t\t\t\t\tbuf = ''\n",
    "\t\t\t\n",
    "\t\t\tif not buf:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\ttarget.send(Lexemere('atom', EOF))\n",
    "\t\t\t\texcept StopIteration:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\tbreak\n",
    "\n",
    "@coroutine\n",
    "def print_coro():\n",
    "    while True:\n",
    "        x = yield\n",
    "        print(x)\n",
    "coro = lexer(print_coro())\n",
    "coro.send('{\"a\": hello world}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
